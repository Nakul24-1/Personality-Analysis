{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NEU trait RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJcAI5ZCSK6vEWbcS8k2Fh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nakul24-1/Personality-Analysis/blob/master/Copy_of_NEU_trait_RoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5XOPYoB7Ivx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7021b482-7819-47e9-9762-863644959e42"
      },
      "source": [
        "import pandas as pd\n",
        "!pip install transformers==3.5.1\n",
        "!pip install tensorflow\n",
        "\n",
        "# Recommended tensorflow version is <= 2.1.0, otherwise F1 score function breaks\n",
        "\n",
        "from transformers import RobertaModel\n",
        "from transformers import RobertaTokenizer\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (20.9)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/ac/f5ba028f0f097d855e1541301e946d4672eb0f30b6e25cb2369075f916d2/tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.1) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (54.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=52a0a376b1183d0794142ea8029187db2deac812ecc5176c6209ce081aa14f9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-12a44770d513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Recommended tensorflow version is <= 2.1.0, otherwise F1 score function breaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobertaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_pt_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 69\u001b[0;31m from .trainer_pt_utils import (\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mDistributedTensorGatherer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mSequentialDistributedSampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSAVE_STATE_WARNING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAVE_STATE_WARNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'SAVE_STATE_WARNING' from 'torch.optim.lr_scheduler' (/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rHcqAZYyCDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4d3ed9-f980-466a-f620-9f7e6e280855"
      },
      "source": [
        "import torch\r\n",
        "torch.version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.version' from '/usr/local/lib/python3.7/dist-packages/torch/version.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsINK7vc8YQX"
      },
      "source": [
        "train_tweets = pd.read_csv('essays2007.csv')\n",
        "#test_tweets = pd.read_csv('test_tweets.csv')\n",
        "\n",
        "#test_tweets['label'] = 0\n",
        "\n",
        "training_sentences, testing_sentences = train_test_split(train_tweets[['text', 'cNEU']],\n",
        "                                                         test_size=0.2)\n",
        "\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\",use_fast=False)\n",
        "\n",
        "# can be up to 512 for BERT\n",
        "max_length = 350\n",
        "\n",
        "# the recommended batches size for BERT are 32,64 ... however on this dataset we are overfitting quite fast\n",
        "# and smaller batches work like a regularization.\n",
        "# You might play with adding another dropout layer instead.(**Have to explore this**)\n",
        "\n",
        "batch_size = 16\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGai_XUeHq9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "b84fda52-a374-4285-ecdf-a434ae28b679"
      },
      "source": [
        "testing_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cNEU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>Psychology is a class that I have always been ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>This is probably the weirdest writing assignme...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2394</th>\n",
              "      <td>Today was a long day. I have been going none s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>Ouch, that hurts. Damn, damn, damn. I really...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>I am an architecture major. Therefore I do not...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2455</th>\n",
              "      <td>I'm finally getting around to typing this stre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>Well, I'm listening to 0 Doors Down. My friend...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1352</th>\n",
              "      <td>I'm sitting in the library at 0:00am once agai...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>I guess I won't be looking forward to this wee...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>Wow, I'm pretty tired right now it's been a he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>494 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  cNEU\n",
              "1499  Psychology is a class that I have always been ...     1\n",
              "1104  This is probably the weirdest writing assignme...     0\n",
              "2394  Today was a long day. I have been going none s...     0\n",
              "229     Ouch, that hurts. Damn, damn, damn. I really...     0\n",
              "1033  I am an architecture major. Therefore I do not...     1\n",
              "...                                                 ...   ...\n",
              "2455  I'm finally getting around to typing this stre...     0\n",
              "1936  Well, I'm listening to 0 Doors Down. My friend...     0\n",
              "1352  I'm sitting in the library at 0:00am once agai...     1\n",
              "265   I guess I won't be looking forward to this wee...     1\n",
              "310   Wow, I'm pretty tired right now it's been a he...     1\n",
              "\n",
              "[494 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-suBUGc8gZM"
      },
      "source": [
        "def convert_example_to_feature(review):\n",
        "    # combine step for tokenization, WordPiece vector mapping and will\n",
        "    # add also special tokens and truncate reviews longer than our max length\n",
        "    return roberta_tokenizer.encode_plus(review,\n",
        "                                 add_special_tokens=True,  # add [CLS], [SEP]\n",
        "                                 max_length=max_length,  # max length of the text that can go to RoBERTa\n",
        "                                 pad_to_max_length=True,  # add [PAD] tokens at the end of sentence\n",
        "                                 return_attention_mask=True,  # add attention mask to not focus on pad tokens\n",
        "                                 truncation = True,\n",
        "                                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9IwAqS8jE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8de815-c18b-45b7-c155-4014985645d5"
      },
      "source": [
        "def map_example_to_dict(input_ids, attention_masks, label):\n",
        "    return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "           }, label\n",
        "\n",
        "def encode_examples(ds, limit=-1):\n",
        "    # Prepare Input list\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    label_list = []\n",
        "\n",
        "\n",
        "    if (limit > 0):\n",
        "        ds = ds.take(limit)\n",
        "\n",
        "    for review, label in tfds.as_numpy(ds):\n",
        "        bert_input = convert_example_to_feature(review.decode())\n",
        "        input_ids_list.append((bert_input['input_ids']))\n",
        "        attention_mask_list.append((bert_input['attention_mask']))\n",
        "        label_list.append([label])\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((input_ids_list,\n",
        "                                               attention_mask_list,\n",
        "                                               label_list)).map(map_example_to_dict)\n",
        "\n",
        "training_sentences_modified = tf.data.Dataset.from_tensor_slices((training_sentences['text'],\n",
        "                                                                  training_sentences['cNEU']))\n",
        "\n",
        "testing_sentences_modified = tf.data.Dataset.from_tensor_slices((testing_sentences['text'],\n",
        "                                                                 testing_sentences['cNEU']))\n",
        "\n",
        "ds_train_encoded = encode_examples(training_sentences_modified).shuffle(10000).batch(batch_size)\n",
        "ds_test_encoded = encode_examples(testing_sentences_modified).batch(batch_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLTAIXaIlHaE",
        "outputId": "9b032887-281a-4bbf-bd94-18b446442595"
      },
      "source": [
        "ds_test_encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 350), (None, 350), (None, 1)), types: (tf.int32, tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBDiXjTc8nlJ"
      },
      "source": [
        "learning_rate = 8e-6\n",
        "number_of_epochs = 8\n",
        "class ModelMetrics(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.count_n = 1\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        \n",
        "        os.makedirs('/model' + str(self.count_n),exist_ok=True)\n",
        "        self.model.save_pretrained('/model' + str(self.count_n)) # this folder address should match with folder we created above\n",
        "        \n",
        "        y_val_pred = tf.nn.softmax(self.model.predict(ds_test_encoded))\n",
        "        y_pred_argmax = tf.math.argmax(y_val_pred, axis=1)\n",
        "        #testing_copy = testing_sentences.copy()\n",
        "        #testing_copy['predicted'] = y_pred_argmax\n",
        "        #f1_s = f1_score(testing_sentences['cAGR'], testing_copy['predicted'])\n",
        "        #print('\\n f1 score is :', f1_s)\n",
        "        self.count_n += 1\n",
        "\n",
        "metrics = ModelMetrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPEAqsUp8wtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec178a2-9e58-4a36-eb61-02b08a0ad6f2"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ModelMetrics at 0x7f4a4fc88b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE6VetFq-Hp_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ce8c7be-0fb2-4fc3-8cce-a085b1ade4a5"
      },
      "source": [
        "model = RobertaModel.from_pretrained(\"roberta-base\",return_dict = False)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08) #maybe try diff values here\n",
        "model.summary()\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "#model.add(layers.dropout(0.5))\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "model.fit(ds_train_encoded, epochs=number_of_epochs,\n",
        "          validation_data=ds_test_encoded, callbacks=[metrics])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_roberta_for_sequence_classification_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "roberta (TFRobertaMainLayer) multiple                  124055040 \n",
            "_________________________________________________________________\n",
            "classifier (TFRobertaClassif multiple                  592130    \n",
            "=================================================================\n",
            "Total params: 124,647,170\n",
            "Trainable params: 124,647,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5044WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "124/124 [==============================] - 188s 1s/step - loss: 0.6950 - accuracy: 0.5044 - val_loss: 0.6935 - val_accuracy: 0.4757\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b4553d182d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m model.fit(ds_train_encoded, epochs=number_of_epochs,\n\u001b[0;32m---> 10\u001b[0;31m           validation_data=ds_test_encoded, callbacks=[metrics])\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-a5921095c831>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this folder address should match with folder we created above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0my_pred_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#testing_copy = testing_sentences.copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_v2\u001b[0;34m(logits, axis, name)\u001b[0m\n\u001b[1;32m   3732\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3733\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3734\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_2d_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_wrap_2d_function\u001b[0;34m(inputs, compute_op, dim, name)\u001b[0m\n\u001b[1;32m   3611\u001b[0m         name=name)\n\u001b[1;32m   3612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3613\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m   \u001b[0;31m# We need its original shape for shape inference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (TFSequenceClassifierOutput(loss=None, logits=array([[ 0.07337884,  0.03461943],\n       [ 0.07594519,  0.02884015],\n       [ 0.0879768 ,  0.01864901],\n       [ 0.0710893 ,  0.03657067],\n       [ 0.0599557 ,  0.03871783],\n       [ 0.07303431,  0.02381565],\n       [ 0.08247324,  0.01946255],\n       [ 0.0880719 ,  0.01997538],\n       [ 0.07308591,  0.0269312 ],\n       [ 0.08082595,  0.02203168],\n       [ 0.08068451,  0.02728566],\n       [ 0.07998854,  0.02695402],\n       [ 0.05853898,  0.03128085],\n       [ 0.07385574,  0.02386578],\n       [ 0.08895624,  0.01398801],\n       [ 0.1125214 ,  0.0130023 ],\n       [ 0.08086571,  0.02688446],\n       [ 0.07193689,  0.02924445],\n       [ 0.06918135,  0.03134502],\n       [ 0.06376508,  0.03307823],\n       [ 0.06826583,  0.02268635],\n       [ 0.08248095,  0.02777906],\n       [ 0.08571205,  0.01846267],\n       [ 0.10972565,  0.00649126],\n       [ 0.10419419,  0.01286824],\n       [ 0.06274207,  0.03211796],\n       [ 0.08828365,  0.02373879],\n       [ 0.08171693,  0.02277543],\n       [ 0.07800168,  0.02613601],\n       [ 0.06668883,  0.03758863],\n       [ 0.08917312,  0.01403175],\n       [ 0.06152309,  0.02861952],\n       [ 0.06481712,  0.02875434],\n       [ 0.07987162,  0.01684164],\n       [ 0.08104853,  0.02016471],\n       [ 0.08926924,  0.01432338],\n       [ 0.07623571,  0.02138566],\n       [ 0.08697526,  0.01867205],\n       [ 0.06954024,  0.02699102],\n       [ 0.09305529,  0.01592097],\n       [ 0.0853254 ,  0.01769347],\n       [ 0.07407187,  0.02810411],\n       [ 0.0778509 ,  0.02218685],\n       [ 0.07444692,  0.03377104],\n       [ 0.0749702 ,  0.0229953 ],\n       [ 0.05073461,  0.04155525],\n       [ 0.06470611,  0.03602254],\n       [ 0.08878434,  0.01688771],\n       [ 0.06781652,  0.03074078],\n       [ 0.10521181,  0.01086255],\n       [ 0.06315961,  0.03020802],\n       [ 0.08433697,  0.0304217 ],\n       [ 0.10868641,  0.00678203],\n       [ 0.06674706,  0.03127307],\n       [ 0.06899281,  0.02856453],\n       [ 0.07531743,  0.02195858],\n       [ 0.07877812,  0.0272461 ],\n       [ 0.06998883,  0.02637134],\n       [ 0.08856486,  0.01992507],\n       [ 0.08731798,  0.0257312 ],\n       [ 0.0759425 ,  0.02714201],\n       [ 0.0834749 ,  0.022519  ],\n       [ 0.06124943,  0.03703072],\n       [ 0.10464462,  0.01416717],\n       [ 0.09749098,  0.00590312],\n       [ 0.06376237,  0.0384693 ],\n       [ 0.07534755,  0.02690597],\n       [ 0.07025924,  0.02148313],\n       [ 0.07280751,  0.02238195],\n       [ 0.0747785 ,  0.02791482],\n       [ 0.09003207,  0.0134766 ],\n       [ 0.07832757,  0.02241368],\n       [ 0.06558295,  0.02488578],\n       [ 0.08216703,  0.02237657],\n       [ 0.07738809,  0.01971943],\n       [ 0.07846104,  0.0209287 ],\n       [ 0.08685534,  0.01642179],\n       [ 0.07861868,  0.02974064],\n       [ 0.06680363,  0.02805502],\n       [ 0.07780118,  0.02480185],\n       [ 0.07564883,  0.02750258],\n       [ 0.06712075,  0.03675045],\n       [ 0.07315288,  0.02626918],\n       [ 0.0666365 ,  0.0379209 ],\n       [ 0.08803838,  0.02059366],\n       [ 0.09080063,  0.01339587],\n       [ 0.07723033,  0.02484705],\n       [ 0.08893935,  0.02326123],\n       [ 0.07597688,  0.02191724],\n       [ 0.08565629,  0.02012881],\n       [ 0.09390993,  0.02425273],\n       [ 0.06953818,  0.03396459],\n       [ 0.06735559,  0.03094201],\n       [ 0.08037893,  0.02429515],\n       [ 0.08946283,  0.01745437],\n       [ 0.08727857,  0.02240701],\n       [ 0.07013961,  0.03244772],\n       [ 0.06545008,  0.03643839],\n       [ 0.08514926,  0.02192822],\n       [ 0.0844069 ,  0.02650605],\n       [ 0.0751169 ,  0.02082779],\n       [ 0.07971402,  0.02120481],\n       [ 0.08382095,  0.01986861],\n       [ 0.08062303,  0.02356017],\n       [ 0.08594371,  0.01710966],\n       [ 0.06843154,  0.03020231],\n       [ 0.07239317,  0.03002066],\n       [ 0.06207298,  0.03008438],\n       [ 0.09815541,  0.01242734],\n       [ 0.08584958,  0.02478684],\n       [ 0.06324726,  0.03701279],\n       [ 0.0801281 ,  0.02305193],\n       [ 0.08157264,  0.02102426],\n       [ 0.07926568,  0.0284039 ],\n       [ 0.1005133 ,  0.00501047],\n       [ 0.07917778,  0.02315233],\n       [ 0.08861492,  0.01618126],\n       [ 0.08826723,  0.01233181],\n       [ 0.07054196,  0.03518348],\n       [ 0.05640551,  0.02922798],\n       [ 0.08560959,  0.02104969],\n       [ 0.06877559,  0.02863097],\n       [ 0.07606801,  0.01493014],\n       [ 0.0874124 ,  0.01181906],\n       [ 0.07433863,  0.02991519],\n       [ 0.07413016,  0.01744461],\n       [ 0.0839186 ,  0.02254459],\n       [ 0.0712335 ,  0.03356915],\n       [ 0.0755448 ,  0.03282975],\n       [ 0.0832764 ,  0.0213371 ],\n       [ 0.08496408,  0.02802568],\n       [ 0.04327761,  0.05241166],\n       [ 0.06451464,  0.03069074],\n       [ 0.08277921,  0.0181495 ],\n       [ 0.07702433,  0.02230161],\n       [ 0.10554585,  0.01079986],\n       [ 0.08750282,  0.01377247],\n       [ 0.07024633,  0.02435713],\n       [ 0.09045219,  0.01792952],\n       [ 0.08436964,  0.0240862 ],\n       [ 0.07085258,  0.02464812],\n       [ 0.06637395,  0.03613622],\n       [ 0.08382917,  0.02309414],\n       [ 0.0717781 ,  0.03385062],\n       [ 0.09122217,  0.01664163],\n       [ 0.06925804,  0.02578366],\n       [ 0.10117426,  0.02387032],\n       [ 0.06657237,  0.02862187],\n       [ 0.07122649,  0.02943289],\n       [ 0.0622423 ,  0.03190914],\n       [ 0.08431382,  0.01994328],\n       [ 0.08275359,  0.02465805],\n       [ 0.05775749,  0.04096599],\n       [ 0.05650941,  0.03225208],\n       [ 0.07191566,  0.02749556],\n       [ 0.07463089,  0.0226106 ],\n       [ 0.072716  ,  0.02434167],\n       [ 0.10397675,  0.00604387],\n       [ 0.06824406,  0.0336341 ],\n       [ 0.08295964,  0.01850269],\n       [ 0.09624646,  0.01621788],\n       [ 0.07864321,  0.02787826],\n       [ 0.08188797,  0.0269136 ],\n       [ 0.08103925,  0.02225724],\n       [ 0.10509515,  0.01581912],\n       [ 0.07258834,  0.02668019],\n       [ 0.09549385,  0.00949772],\n       [ 0.0745108 ,  0.02639998],\n       [ 0.06812471,  0.02940405],\n       [ 0.07316497,  0.02503021],\n       [ 0.0917574 ,  0.02404828],\n       [ 0.0673863 ,  0.02710574],\n       [ 0.08705137,  0.02502317],\n       [ 0.07392943,  0.03054004],\n       [ 0.08737127,  0.02078323],\n       [ 0.05942328,  0.03591518],\n       [ 0.07297185,  0.02847932],\n       [ 0.07594497,  0.02647029],\n       [ 0.06638002,  0.03608989],\n       [ 0.07901827,  0.02189379],\n       [ 0.08241345,  0.02465466],\n       [ 0.09024142,  0.02012673],\n       [ 0.06643786,  0.03510332],\n       [ 0.09482896,  0.0222031 ],\n       [ 0.08034751,  0.02364131],\n       [ 0.09427295,  0.03275672],\n       [ 0.07270611,  0.02722084],\n       [ 0.07785971,  0.02329957],\n       [ 0.08191952,  0.02355622],\n       [ 0.0498649 ,  0.04107288],\n       [ 0.08552857,  0.02389986],\n       [ 0.09157996,  0.02241579],\n       [ 0.08589509,  0.02076052],\n       [ 0.08270308,  0.01710818],\n       [ 0.06617472,  0.03793654],\n       [ 0.06254064,  0.03286899],\n       [ 0.0822797 ,  0.02663137],\n       [ 0.07460865,  0.02432936],\n       [ 0.0628369 ,  0.03884373],\n       [ 0.07520703,  0.0306954 ],\n       [ 0.06926644,  0.02890355],\n       [ 0.0940612 ,  0.02393489],\n       [ 0.10969272,  0.00665529],\n       [ 0.08340704,  0.02472978],\n       [ 0.07316983,  0.03165019],\n       [ 0.07935213,  0.01953079],\n       [ 0.08072503,  0.02622446],\n       [ 0.07087365,  0.02181268],\n       [ 0.0926233 ,  0.01250578],\n       [ 0.07519258,  0.02905166],\n       [ 0.06468218,  0.02832269],\n       [ 0.07282995,  0.02557285],\n       [ 0.0725463 ,  0.02119887],\n       [ 0.0611713 ,  0.03619973],\n       [ 0.07520612,  0.02300393],\n       [ 0.09192324,  0.01606829],\n       [ 0.10970265,  0.00355884],\n       [ 0.07347005,  0.01601304],\n       [ 0.06166496,  0.02431863],\n       [ 0.07383485,  0.03244594],\n       [ 0.07121243,  0.0304773 ],\n       [ 0.0704978 ,  0.03013044],\n       [ 0.08311476,  0.024576  ],\n       [ 0.07876594,  0.02377387],\n       [ 0.07809258,  0.02771009],\n       [ 0.06725147,  0.02778983],\n       [ 0.08047607,  0.02702039],\n       [ 0.08607916,  0.02642815],\n       [ 0.08015077,  0.01954907],\n       [ 0.08335564,  0.02067361],\n       [ 0.08983356,  0.02006098],\n       [ 0.06158561,  0.03497672],\n       [ 0.07883299,  0.02148869],\n       [ 0.06852721,  0.01829187],\n       [ 0.08072564,  0.02270446],\n       [ 0.07312507,  0.01920705],\n       [ 0.0713215 ,  0.02483943],\n       [ 0.08895601,  0.0168509 ],\n       [ 0.09173994,  0.0195527 ],\n       [ 0.09711619,  0.01287431],\n       [ 0.0854752 ,  0.01704577],\n       [ 0.08722229,  0.01775834],\n       [ 0.08952935,  0.0212265 ],\n       [ 0.08628731,  0.01909868],\n       [ 0.06999264,  0.02904906],\n       [ 0.07791439,  0.02893033],\n       [ 0.09117515,  0.02371351],\n       [ 0.06425694,  0.04567643],\n       [ 0.07559747,  0.03269588],\n       [ 0.07343282,  0.02905967],\n       [ 0.06980808,  0.03339823],\n       [ 0.06971736,  0.02982306],\n       [ 0.07881093,  0.02426864],\n       [ 0.07421747,  0.02670609],\n       [ 0.08059769,  0.01931437],\n       [ 0.09738407,  0.015136  ],\n       [ 0.07703532,  0.02920021],\n       [ 0.04609508,  0.05053515],\n       [ 0.07971471,  0.0256659 ],\n       [ 0.05177961,  0.0434267 ],\n       [ 0.0815579 ,  0.02171326],\n       [ 0.05146008,  0.04166087],\n       [ 0.08747701,  0.02351785],\n       [ 0.0739793 ,  0.03280162],\n       [ 0.10481049,  0.01073077],\n       [ 0.06866401,  0.01862012],\n       [ 0.07112807,  0.01935786],\n       [ 0.05615262,  0.02643968],\n       [ 0.08261728,  0.0109156 ],\n       [ 0.05715441,  0.0339918 ],\n       [ 0.08480018,  0.02325143],\n       [ 0.09146114,  0.01867146],\n       [ 0.05782134,  0.04005361],\n       [ 0.09625236,  0.01049355],\n       [ 0.05459182,  0.0438394 ],\n       [ 0.06932364,  0.02686519],\n       [ 0.05788287,  0.03652596],\n       [ 0.08970514,  0.01356792],\n       [ 0.06390164,  0.02843798],\n       [ 0.0640399 ,  0.03187606],\n       [ 0.08067581,  0.02611094],\n       [ 0.07516866,  0.03026639],\n       [ 0.08254965,  0.01832917],\n       [ 0.07743242,  0.02107681],\n       [ 0.06075135,  0.03451966],\n       [ 0.06488091,  0.03116134],\n       [ 0.09510817,  0.01644613],\n       [ 0.07699896,  0.01559229],\n       [ 0.08839951,  0.01895944],\n       [ 0.07754917,  0.01762603],\n       [ 0.06518524,  0.02054762],\n       [ 0.08099836,  0.01984031],\n       [ 0.08735511,  0.02710808],\n       [ 0.08471408,  0.02345712],\n       [ 0.06637472,  0.02774024],\n       [ 0.06862044,  0.02767998],\n       [ 0.04948053,  0.0368828 ],\n       [ 0.0622624 ,  0.0406451 ],\n       [ 0.09038703,  0.01968297],\n       [ 0.07006902,  0.02521234],\n       [ 0.06892145,  0.02719958],\n       [ 0.06036203,  0.03595234],\n       [ 0.06408665,  0.02935841],\n       [ 0.05988745,  0.0416474 ],\n       [ 0.07529565,  0.02942601],\n       [ 0.09255518,  0.01276813],\n       [ 0.0705063 ,  0.0197944 ],\n       [ 0.0863421 ,  0.01867918],\n       [ 0.07490198,  0.02868601],\n       [ 0.09417216,  0.01750771],\n       [ 0.04616385,  0.04387718],\n       [ 0.07063958,  0.02422334],\n       [ 0.09805131,  0.01237452],\n       [ 0.097761  ,  0.00908265],\n       [ 0.07350555,  0.02900514],\n       [ 0.08044977,  0.02157711],\n       [ 0.09020121,  0.01956222],\n       [ 0.08209708,  0.02644287],\n       [ 0.07283825,  0.02462963],\n       [ 0.07734667,  0.02894061],\n       [ 0.06446055,  0.03709568],\n       [ 0.09005506,  0.01335788],\n       [ 0.09511794,  0.01343636],\n       [ 0.08153502,  0.02366149],\n       [ 0.08319344,  0.02816313],\n       [ 0.0584476 ,  0.03636292],\n       [ 0.10067947,  0.01312068],\n       [ 0.07351007,  0.02847316],\n       [ 0.07572339,  0.02763989],\n       [ 0.0877413 ,  0.01782563],\n       [ 0.07483438,  0.01881456],\n       [ 0.08135589,  0.01840183],\n       [ 0.09811599,  0.01717026],\n       [ 0.05935732,  0.0364913 ],\n       [ 0.05890833,  0.03024669],\n       [ 0.08533539,  0.02228841],\n       [ 0.0620696 ,  0.0340735 ],\n       [ 0.09143605,  0.02333937],\n       [ 0.07746106,  0.03053871],\n       [ 0.08413289,  0.01030303],\n       [ 0.06274516,  0.03428315],\n       [ 0.09462887,  0.02048527],\n       [ 0.09477419,  0.02149561],\n       [ 0.08169633,  0.02225616],\n       [ 0.07220378,  0.02240989],\n       [ 0.09381299,  0.01615103],\n       [ 0.08206034,  0.02765467],\n       [ 0.07420741,  0.02977376],\n       [ 0.07892077,  0.0294165 ],\n       [ 0.08267848,  0.02013977],\n       [ 0.06106051,  0.0333479 ],\n       [ 0.08838831,  0.02496125],\n       [ 0.0574195 ,  0.03984085],\n       [ 0.05598105,  0.04027465],\n       [ 0.09287068,  0.02252612],\n       [ 0.08480442,  0.02882204],\n       [ 0.05780848,  0.04134853],\n       [ 0.07917134,  0.02045856],\n       [ 0.09511703,  0.01892684],\n       [ 0.07480995,  0.01596448],\n       [ 0.07114644,  0.02568567],\n       [ 0.0629046 ,  0.03380183],\n       [ 0.0782346 ,  0.02650375],\n       [ 0.07804408,  0.0269392 ],\n       [ 0.10225977,  0.00598884],\n       [ 0.08351357,  0.02045666],\n       [ 0.0673358 ,  0.03206845],\n       [ 0.08977089,  0.02440746],\n       [ 0.07303361,  0.02464912],\n       [ 0.08552942,  0.02241819],\n       [ 0.0852555 ,  0.02033609],\n       [ 0.08584149,  0.02514144],\n       [ 0.08007437,  0.02246292],\n       [ 0.06020385,  0.0349048 ],\n       [ 0.1003405 ,  0.01310256],\n       [ 0.072323  ,  0.02561221],\n       [ 0.0789023 ,  0.02531096],\n       [ 0.07512258,  0.03168073],\n       [ 0.09172155,  0.01493562],\n       [ 0.07310639,  0.01786698],\n       [ 0.08553132,  0.01806745],\n       [ 0.08411109,  0.0214301 ],\n       [ 0.06490692,  0.02711248],\n       [ 0.06574173,  0.03240941],\n       [ 0.05136389,  0.03496093],\n       [ 0.07987621,  0.01189187],\n       [ 0.07646683,  0.02446693],\n       [ 0.08317922,  0.01954949],\n       [ 0.10166185,  0.01642914],\n       [ 0.06629712,  0.03772609],\n       [ 0.07985091,  0.02540567],\n       [ 0.10685907,  0.00409958],\n       [ 0.06784953,  0.02284555],\n       [ 0.06770819,  0.02518675],\n       [ 0.10236447,  0.00942314],\n       [ 0.08951399,  0.01623077],\n       [ 0.08566748,  0.0118982 ],\n       [ 0.08464567,  0.018752  ],\n       [ 0.07631913,  0.02920712],\n       [ 0.09332481,  0.01900364],\n       [ 0.07931828,  0.02120544],\n       [ 0.06916153,  0.03190039],\n       [ 0.07519042,  0.02771879],\n       [ 0.08615118,  0.02787762],\n       [ 0.09107681,  0.01539788],\n       [ 0.11751685, -0.00114996],\n       [ 0.07911287,  0.02110486],\n       [ 0.06595987,  0.03000876],\n       [ 0.0805994 ,  0.02167608],\n       [ 0.08814898,  0.02182426],\n       [ 0.07817663,  0.02490054],\n       [ 0.08515415,  0.02843722],\n       [ 0.07940418,  0.02746084],\n       [ 0.0798116 ,  0.01304699],\n       [ 0.07117676,  0.03256657],\n       [ 0.08169641,  0.02302116],\n       [ 0.07676097,  0.02852556],\n       [ 0.07313126,  0.03548625],\n       [ 0.07455534,  0.03117494],\n       [ 0.06241976,  0.03619568],\n       [ 0.09615241,  0.01987668],\n       [ 0.09497362,  0.00725502],\n       [ 0.08409242,  0.01923213],\n       [ 0.08317798,  0.01365338],\n       [ 0.08783993,  0.01576267],\n       [ 0.05351393,  0.03432872],\n       [ 0.08828575,  0.01662911],\n       [ 0.09225731,  0.02451895],\n       [ 0.06765006,  0.03349777],\n       [ 0.05727243,  0.03695689],\n       [ 0.09367965,  0.0078165 ],\n       [ 0.07917222,  0.02623454],\n       [ 0.0730519 ,  0.02445126],\n       [ 0.07980122,  0.02246161],\n       [ 0.0823972 ,  0.01728129],\n       [ 0.08392907,  0.01985713],\n       [ 0.07477335,  0.02552866],\n       [ 0.08255301,  0.02093313],\n       [ 0.09242475,  0.01652928],\n       [ 0.08816201,  0.01935548],\n       [ 0.09355977,  0.00893137],\n       [ 0.07849125,  0.0280754 ],\n       [ 0.09935052,  0.01605735],\n       [ 0.07310657,  0.02280611],\n       [ 0.08937456,  0.01685604],\n       [ 0.07169856,  0.02776201],\n       [ 0.09411563,  0.01751016],\n       [ 0.07588077,  0.02634419],\n       [ 0.08828995,  0.0239502 ],\n       [ 0.05485066,  0.03957423],\n       [ 0.0855386 ,  0.02530027],\n       [ 0.05543964,  0.0336676 ],\n       [ 0.07989489,  0.02556608],\n       [ 0.07384542,  0.0310753 ],\n       [ 0.08728169,  0.02606856],\n       [ 0.09145133,  0.01592989],\n       [ 0.08869264,  0.01751667],\n       [ 0.06842692,  0.02415166],\n       [ 0.07812195,  0.01977633],\n       [ 0.07455309,  0.02548522],\n       [ 0.09248192,  0.01241936],\n       [ 0.08504075,  0.02197487],\n       [ 0.07677902,  0.02385708],\n       [ 0.07093801,  0.01991176],\n       [ 0.08392794,  0.02139897],\n       [ 0.06256093,  0.03579839],\n       [ 0.06966325,  0.03547382],\n       [ 0.06382869,  0.03259642],\n       [ 0.08745655,  0.01797397],\n       [ 0.07105836,  0.02727897],\n       [ 0.06780395,  0.02574615],\n       [ 0.07824957,  0.02838677],\n       [ 0.08063643,  0.02516187],\n       [ 0.07999526,  0.02530255],\n       [ 0.06468917,  0.03356424],\n       [ 0.06398158,  0.02391077],\n       [ 0.07238442,  0.03088637],\n       [ 0.07749318,  0.02512052],\n       [ 0.08001743,  0.02353091],\n       [ 0.07642945,  0.02290265],\n       [ 0.05123164,  0.0402653 ],\n       [ 0.08314662,  0.02575077],\n       [ 0.07188654,  0.02266929],\n       [ 0.06544753,  0.02606648],\n       [ 0.06227639,  0.02515124],\n       [ 0.0822282 ,  0.02658064],\n       [ 0.07237221,  0.0283421 ],\n       [ 0.09053243,  0.01060833],\n       [ 0.0692564 ,  0.03020797],\n       [ 0.07156682,  0.02438363],\n       [ 0.07945794,  0.01990343],\n       [ 0.06589945,  0.02958371],\n       [ 0.06725372,  0.02940698],\n       [ 0.08539252,  0.02012906]], dtype=float32), hidden_states=None, attentions=None)) with an unsupported type (<class 'transformers.modeling_tf_outputs.TFSequenceClassifierOutput'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhT9l20i-L78"
      },
      "source": [
        "comment_dataframe = pd.read_csv('FYP_Dataset1.csv')\r\n",
        "comment_dataframe['label'] = 0\r\n",
        "print(comment_dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XxsB2MRIVHI"
      },
      "source": [
        "def encode_examples(ds, limit=-1):\r\n",
        "    # Prepare Input list\r\n",
        "    input_ids_list = []\r\n",
        "    attention_mask_list = []\r\n",
        "    label_list = []\r\n",
        "\r\n",
        "    if (limit > 0):\r\n",
        "        ds = ds.take(limit)\r\n",
        "\r\n",
        "    for review, label in tfds.as_numpy(ds):\r\n",
        "        bert_input = convert_example_to_feature(review.decode())\r\n",
        "        input_ids_list.append(bert_input['input_ids'])\r\n",
        "        attention_mask_list.append(bert_input['attention_mask'])\r\n",
        "        label_list.append([label])\r\n",
        "\r\n",
        "    return tf.data.Dataset.from_tensor_slices((input_ids_list,\r\n",
        "                                               attention_mask_list,\r\n",
        "                                               label_list)).map(map_example_to_dict)\r\n",
        "\r\n",
        "submission_sentences_modified = tf.data.Dataset.from_tensor_slices((comment_dataframe['Essay'],\r\n",
        "                                                                            comment_dataframe['pred_val']))\r\n",
        "ds_submission_encoded = encode_examples(submission_sentences_modified).batch(batch_size)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "submission_pre = tf.nn.softmax(model.predict(ds_submission_encoded))\r\n",
        "submission_pre_argmax = tf.math.argmax(submission_pre, axis=1)\r\n",
        "print(np.array(submission_pre[0]))\r\n",
        "comment_dataframe['pred_val'] = (np.array(submission_pre[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBE8YArCtrIc"
      },
      "source": [
        "newdf=comment_dataframe[['Name','Neurotism','pred_val']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jI0tp0HtykG"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "x = np.array(newdf['Extraversion']) #returns a numpy array\r\n",
        "newdf.iloc[:,1:-1] = newdf.iloc[:,1:-1].apply(lambda x: (x-30)/ (120-30), axis=0)\r\n",
        "newdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuLdJ7VIyeNk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}